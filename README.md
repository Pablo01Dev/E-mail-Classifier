# ğŸ“§ AutoMail Classifier â€” ClassificaÃ§Ã£o Inteligente de E-mails com IA
---

Esta Ã© uma aplicaÃ§Ã£o web desenvolvida com **FastAPI (backend)** e **React + Vite (frontend)**, projetada para automatizar a triagem de e-mails em ambientes de alto volume, classificando e sugerindo respostas automÃ¡ticas.

---

## âœ¨ Funcionalidades Principais

* **ClassificaÃ§Ã£o AutomÃ¡tica**
  Categoriza e-mails em **Produtivo** ou **Improdutivo** usando um modelo hÃ­brido (Regras + TF-IDF/LogReg).

* **SugestÃ£o AutomÃ¡tica de Resposta**
  Gera uma resposta adequada ao contexto e Ã  categoria detectada.

---

# ğŸš€ Como Rodar Localmente

## 1. Clone o repositÃ³rio

```bash
git clone https://github.com/SEU_USUARIO/automail-classifier.git
cd automail-classifier
```

A estrutura geral agora Ã©:

```
backend/
frontend/
```

---

# ğŸ–¥ï¸ Backend (FastAPI)

## 2. Criar ambiente virtual e instalar dependÃªncias

```bash
cd backend

python -m venv .venv
# Linux/Mac
source .venv/bin/activate
# Windows
# .venv\Scripts\activate

pip install -r requirements.txt
```

## 3. Configurar a chave API

1. Copie o arquivo `.env.example` para `.env`
2. Substitua `YOUR_API_KEY_HERE` pela sua chave real

âš ï¸ NÃ£o faÃ§a commit do arquivo `.env`.

## 4. Rodar o backend

```bash
uvicorn app:app --reload --port 8000
```

Backend estarÃ¡ em:
â¡ï¸ [http://localhost:8000](http://localhost:8000)

---

# ğŸ¨ Frontend (React + Vite)

## 1. Instalar dependÃªncias

```bash
cd ../frontend
npm install
```

## 2. Executar o servidor de desenvolvimento

```bash
npm run dev
```

O frontend estarÃ¡ disponÃ­vel em:
â¡ï¸ [http://localhost:5173](http://localhost:5173)

E jÃ¡ estarÃ¡ configurado para se comunicar com o backend em `http://localhost:8000`.

---

# â˜ï¸ Deploy (Render)

### Backend (FastAPI)

1. FaÃ§a **fork** do repositÃ³rio
2. No Render: *New +* â†’ *Web Service*
3. Configure:

   * **Runtime**: Python 3.11
   * **Build command**:

     ```
     pip install -r backend/requirements.txt
     ```
   * **Start command**:

     ```
     uvicorn app:app --host 0.0.0.0 --port $PORT
     ```
4. Adicione as variÃ¡veis de ambiente (ex: `OPENAI_API_KEY`)

### Frontend (React + Vite)

1. Criar novo **Static Site** no Render
2. Configurar:

   * **Build Command**:

     ```
     npm install && npm run build
     ```
   * **Publish Directory**:

     ```
     dist
     ```
3. Se necessÃ¡rio, configurar proxy em `vite.config.js` para o backend

---

# ğŸ“‚ Estrutura do Projeto

```
backend/
â”œâ”€â”€ app.py                 # Ponto de entrada da API
â”œâ”€â”€ classifier.py          # Classificador hÃ­brido + respostas automÃ¡ticas
â”œâ”€â”€ nlp.py                 # PrÃ©-processamento e leitura de arquivos
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env.example

frontend/
â”œâ”€â”€ index.html
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.jsx
â”‚   â”œâ”€â”€ services/api.js
â”œâ”€â”€ package.json
â””â”€â”€ vite.config.js
```

---

# ğŸ§  Como Funciona o Classificador

* **Regras determinÃ­sticas**
  Palavras-chave como â€œprotocoloâ€, â€œstatusâ€, â€œfeliz natalâ€, etc.

* **Modelo TF-IDF + Logistic Regression**
  Treinado em um *seed set* inicial.

* **CombinaÃ§Ã£o HÃ­brida**
  A probabilidade final Ã© a mÃ©dia ponderada entre regras e modelo ML.

* **GeraÃ§Ã£o de Resposta**
  SeleÃ§Ã£o automÃ¡tica via templates especÃ­ficos para cada intenÃ§Ã£o.

---

# ğŸ› ï¸ PrÃ³ximas Melhorias

* Migrar para zero-shot (ex.: `bart-mnli`) ou LLMs (OpenAI / HuggingFace)
* Loop de feedback com *retreinamento*
* DetecÃ§Ã£o e tratamento avanÃ§ado de anexos
* SanitizaÃ§Ã£o de PII para maior seguranÃ§a

---

# ğŸ† Tecnologias Utilizadas

### Backend

* Python
* FastAPI
* scikit-learn
* Uvicorn

### Frontend

* React
* Vite
* CSS
---

# ğŸŒ DemonstraÃ§Ã£o

> [E-mail Classifier](https://e-mail-classifier.vercel.app/)

---

# ğŸ™‹ğŸ»â€â™‚ï¸ Autor

**Pablo GuimarÃ£es**

---

# ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a **MIT**.

---

Se quiser, posso:

âœ… gerar uma versÃ£o *super profissional* estilo open-source
âœ… incluir badges (build passing, license, tech stack)
âœ… adicionar GIF da interface
âœ… montar um README multilÃ­ngue (PT/EN)

SÃ³ pedir!
